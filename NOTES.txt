04/28/2016
6) catch up
-HRBF composition
-HRBF marching

7) make the video thing!

04/27/2016
4) catch up
	-must do some cleanup for the bone extremity points and vertex culling
	-vertex culling probably has to be done per joint-joint pairs -> ok [done]
	-extremity closing samples: basically, need to add extremity points for every joint
	-extremity points are computed from closest vertex to joint -> NOT the joint position itself! this fixes a lot of concerns.
	-normal is aligned with bone direction
	-so the current averaging approach should be ok in most cases, but could lead to very odd results... we'll just not add closing points for anything that isn't really an extremity
	-"not really an extremity" -> "root" joint with multiple children
	-see the paper

	-test up to sampling with debug in Maya/python. [done]
		-just splat the samples on the grid and view to see if it looks right?

		-exporting is turning out to be a mess
		-maya doesn't like it when you try to export files from a maya C++ plugin
		-we'll have to do it through the debugger. ok.
		-in the meantime, let's change things: it's a bad idea to always export all the HRBFs
		-TODO: change HRBF to export a named joint instead of all of them [done]
		-write a python script to visualize [done]

	-finish HRBF build -> matrix solve, fill grids
		-take some time to write a dedicated HRBF3 class and project [done]
		-we'll compare this with Vaillant's implementation [done]
		-reparameterize and fill the grids [done]
		-it should just return 0.0 for anything outside the grid right?
		-make sure grid size is bigger than compact support r [done]
		-do a speed test to see if we need to reduce the samples
			-not HORRIBLY slow in release mode, at least on Calabrese
			-but still not fast. ok, let's add culling down to 60 samples. [done] -> much faster
		-instead of remaking the HRBF objects on every compute call, just resize what you already have. [done]

	-test HRBF build by having Maya fart out HRBFs in python readable [done]
		-although, these could be really, really huge. and we can still only get them out of the debug window
		-it's ok, we only need like one or two to see if it's right

5) build the HRBF manager
	-should handle building the global gradient on another 3D grid from compositions -> we're justing using MAX here
	-this will make exporting relatively easy -> well, "as hard as exporting any single HRBF"
	-should manage all the new inverse TF transforms for querying the individual HRBFs
	-should handle computing all isovalues at the beginning
	-build HRBF composition algorithm:
		-for each HRBF, transform each coordinate A by the bone's matrix
		-get the nearest cell coordinate B in the global HRBF's grid
		-use that coordinate B to get a trilinearly interpolated value from the HRBF -> requires using the inverse of the bone matrix, lol

6) perform HRBF marching


04/26/2016
3D grid and HRBF building
1) build the 3D grid -> separate project with unit tests? could also be useful for [done, maybe more testing?]
	-should take in AABB space bounds and resolution
	-coordinates provided will map to corners of cells: 
		-0,0,0 is AABB min
		-MAX,MAX,MAX is AABB max
	-should have export method to something we can bring into python
	-should be queryable by a position
	-should include trilinear interpolation
	-should be able to ask it for cell center coordinates given 3D idx or 1D idx

2) build the HRBF: the preprocess
	-take in and handle prebindTF and allow querying with world space TF [done]
	-take in a main joint and an optional end joint for producing bone end pts [done]
		-opt end point: prebindTF the translation vector from the opt end matrix [done]
	-should store parallel vectors of normals and positions [done]
	-should handle culling of lousy positions [done]
	-should be equipped to set up the eigen and solve
		-just follow vaillant for now. understand later.

3) strap HRBF activation and debug output into Maya [done]
	-add a dummy control that switches HRBF projection on and off [done]
	-add a control that lets you dump out HRBFs every frame, ala the rebuild HRBF control [done]
	-be able to name individual HRBFs? another attrib, a string array [done]

TOMORROW:

4) catch up
	-test what we have so far using debug mode and Maya
	-finish HRBF build -> matrix solve, fill grids
	-test HRBF build by having Maya fart out HRBFs in python readable
	-write a python script to visualize

5) build the HRBF manager
	-should handle building the global gradient on another 3D grid from compositions -> we're justing using MAX here
	-this will make exporting relatively easy
	-should manage all the new inverse TF transforms for querying the individual HRBFs

6) perform HRBF marching

HRBF Manager
-role is to act as a mediator between the HRBFs and the plugin
	-plugin will provide prebind matrix, positions/normals for each bone
	-plugin will also provide order of positions for computing isovalues
	-btw bind pre matrices don't ever change unless you change the bind pose
		-and btw they aren't just the original tf matrix with some values flipped
		-the order has changed too, which is why the translation isn't just the same thing negated
	-meanwhile, the actual TF matrices maya provides have translation in real space -> great for bones!
		-get these from the bindTFs. otherwise the mats passed in might not be bind, and then we have trouble
	-bind pre's -> just for building the initial HRBFs
	-when we're composing we need to compute inverses of the TFs to get back to HRBF space -> np, maya gives this to us

Notes on how weightsHandle and weightListHandle works
-weights are stored sparsely, hence "if (MS::kSuccess == weightsHandle.jumpToElement(i))"
-weightListHandle is a list of weightsHandles, more or less. MArrayDataHandle
-the HRBF node has an MOBject "weights" that lets you get weightsHandles out of the weightListHandle
-we can reset the weightListHandle using jumpToElement(0) -> seems ok.


*******************************************************************************************************

04/25/2016
3D grid and HRBF
-grid should handle trinilinear interpolation
-we'll set up a separate project for now to develop and test this
-should also handle outputting to python plotting

-HRBF should handle transformation into grid coordinates
-also needs to determine grid bounds from maya point sampling
-also needs to handle filling in the grid
-also needs to handle generating bone end points

-HRBF manager should handle transforming sample points in the global grid into HRBF local space
-this for sampling in HRBF grids to build global grid
-some kind of inverse transform, I think -> run inverse of transform on pt?
-since we're essentially transforming each "bone"

Figuring out the bones
-we NEED to figure out what the matrices we get actually are
-seem to be rotation -> translation matrices of the bones themselves
-and the bind-pre determines how far each vertex is from the bone point
-go look at Adam's slides?

-right. skinning works like this:
	-bind pre matrix translates bone to center and unrotates it
	-then the new matrix rotates it and translates it to wherever it needs to go
	-which is why we do tf * bind pre * point for skinning
-so for querying and building individual grids, we just have to bind pre matrix for every query point
-to rigid transform, just inverse the current joint TF and multiply point by that before querying

04/24/2016
-workflow stages:
1) generate HRBFs
	-compute HRBFs from points and normals -> include smoothness culling
	-we'll also sample down to 50 pts using just random sampling instead of poisson disk -> after smoothness culling
	-compute gradient and field values at each cell in the grid -> check by plotting in python
	-also includes re-parameterization
	-see Vaillant for this (included below)
	-see hrbf_core.h for how to set up the matrix and use eigen

	-each HRBF should store 5 grids:
		-reparamed field function val
		-x, y, z of gradient
		-gradient length

	-HRBF manager only needs to store 4

	-grid should handle trilinear interpolation!
	-grid should also handle text file output

	Tuesday: grid, generate HRBFs
	Wednesday: blend and project

2) blend HRBFs -> done per frame
	-make sure individual HRBF classes have ability to transform point to local coords, get val
	-we'll need a dedicated 3D grid class that will be used for everything
	-should include trilinear interpolation too, really, but... at this point...
	-will be handled internally with GLM
	-the HRBF manager will be responsible for converting between MVector and glm when projecting

	-union operator instead of the gradient based interpolated smooth/union blend for now
	-but how do you union gradient fields? max(length(grad), length(grad))?
	-well... theoretically, grads point to the surface with varying strength
	-stronger further from the surface, right? ok this makes sense, actually. draw it out if you don't believe!
3) project along composed HRBF -> this is done per-frame

// from vaillant distance_field.inl in source code
inline float to_compact_poly_c2(float f, float radius)
{
    if(f < -radius)
        return 1.f;
    else if(f > radius)
        return 0.f;
    else
    {
        // (-3/16)*(f/radius)^5+(5/8)*(f/radius)^3-(15/16)*(f/radius) + 1/2
        const float fact   = (f/radius);
        const float fact2  = fact  * fact;
        const float fact4  = fact2 * fact2;
        return (-3.f/16.f)*fact4*fact + (5.f/8.f)*fact2*fact - (15.f/16.f)*fact + 1.f/2.f;
    }

}
+
// -----------------------------------------------------------------------------

IF_CUDA_DEVICE_HOST
inline void grad_to_compact_poly_c2(float f, float r, Vec3_cu& grad)
{
    if(f < -r || f > r)
        grad = Vec3_cu(0.f,0.f,0.f);
    else
    {
        // (-15/(16r))*(f/r)^4 + (15/(8*r))*(f/r)^2 - (15/(16r))
        const float fact  = f/r;
        const float fact2 = fact*fact;
        const float fact4 = fact2*fact2;
        const float tmp   = (-15.f/(16.f*r));
        const float scale = tmp*fact4 + (15.f/(8.f*r))*fact2 + tmp;
        grad = grad * scale;
    }
}

HRBF_CORE_NOTES
-see at the bottom for where he declares the matrix, alpha and beta arrays
-he does this thing where he typedefs different Eigen matriz sizes to another type name
-maybe we should do this too? for better readability?

04/22/2016
-ok so we should look into the 3D texture HRBF thing
-3D arrays again
-we want to compute an AABB of the HRBF
-ideally we want a resolution such that no two points are in the same cell
-we'll use the average distance between vertices in the iterator?
-alternative: make sure the outermost layer of the AABB has ~enough cells to store all the vertices
-this should be "close" theoretically and may be sufficient. we can double the count if it's bad.
	-faces of a a x b x c voxel grid: a x b x 2 + b x c * 2 + a x c * 2
	-we can set a, b, c to the ratio of the AABB
	-then we just do a x b x 2 + b x c * 2 + a x c * 2 * M = # vertices
	-and then we use M and the ratios to compute the resolution
-although the paper just uses 32x32x32 with trilinear interpolation -> lol
-ok let's do that instead
-the paper also builds the compositions on the fly -> bigger resolution, 128x128x128
-ok

04/21/2016
-observed that when exporting skin weights from HRBF and when exporting from default skincluster, order is different
-HRBF exported skin weights are listed in order that they were bound to the HRBF
-ongoing question: why doesn't this screw LBS over so severely?
-TODO: try adding to skin cluster in DFS order
-if this doesn't work, seriously time to move on to the HRBF part

04/13/2016 - attach hierarchy information to CPP
-do all the attrs stuff -> [DONE] -> that took forever -> that was awful -> ahhhh
-build hierarchy of HRBFs


04/12/2016 - finishing getting HRBF what it needs
-needs joint hierarchy information
	-we can extract relative rotation from matrices
	-we just need to know which matrices go together
	-this likely has to be passed in by MEL
	-we CAN descendants -> get children in MEL
		-so should enforce selecting root. can use list relatives parent to enforce this
		-TODO: write a small hierarchy traversal function in MEL [done]

			listRelatives -c "LeftLeg";

		-this will help us pass hierarchy information to C++
	-how to include this as an attribute though?
		-can we just do this as an attrib array of some kind?
		-clever indexing?
		-could we just do an int array parallel to the matrices?
		-and each item in the array indicates index of parent?
		-we'd be able to get parent transform, which realistically is all we need to compute a full hierarchy in the CPP

	-ok. lesson learned: maya does NOT like you messing with the order of matrices in bind
	-the skin weights for each vertex must be laid out in the same way as listRelatives gets us the matrices -> BOOOOOO
	-need to compute indices of parents based off this ordering! TODO! [DONE]

-ensure that the iterator over points always goes in the same order
	-we'll run some tests

04/08/2016 - getting started with HRBF and HRBF manager
-question: how do we make sure each matrix matches to the right HRBF?
	-do the matrices always come out in the same order?
	-appears to be the case
	-skinning pseudocode:
		-get all the matrices from an iterator
		-look at each point
			-each point has a list of weights -> also in an interator
			-the weights are ordered the same as the matrices from the iterator
		-hopefully this doesn't change in between calls or we'll have some major trouble
-question: how do we extact bone positions from matrices?
	-the transformation itself is an ID
	-the inverse TF matrix is probably where we should do this
-question: how do we extract parent/child info from the matrices?
	-well... there are some "bones" that don't actually have a "next joint" at all
		-see the fingertips
	-so it'd probably be more robust to do this with sampling
	-compute a sampling of joints that are furthest away and use that as a cap

04/06/2016 - fixing DQ, adding HRBF setup
-things to try to fix DQ:
	-try transposing each set of matrices individually -> I think the translation one is right
		-compare side-by-side with Maya's DQ -> ok so I think the matrix access is all fixed
	-try only doing DQ for the local transform and applying the inverse TF as usual

-discovery: with the code as it was at last commit (bug freakout) the translation doesn't do anything on its own! ruh roh!
	-turns out... we weren't building the blended DQ matrix with the right row/column order
	-fixing that makes it do SOMETHING, but it's still wrong
	-something something something affine transform?
	-should probably try the DQ only local transforms thing?
	-do we need to only DQ the local transforms though? [WRONG]
-problem atm seems to be in construction of translation quaternion

03/29/2016 - Setting up HRBFs
-we're going to need a HRBF manager class
-and individual HRBF classes
-all using Maya's underlying math, preferably
-we'll initialize these in deform:
	-on first deform, check if the HRBF manager is null
	-if so, build the HRBF using the data passed in
-can we tie skin weight changes to skin weight changes?
-or can we add a button that calls a method in here to recompute HRBFs?

03/29/2016 - LBS vs. Dual Quaternion
-so the example code implements LBS
-splitting matrix into translate/rotate components:
	-assuming maya rotates and then translates, easy as just accessing portions
-need way to make quat from 3x3 rotaiton -> http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/
-adam's slides are really good, very implementation rich
	-breaks down to:
	-get rotation quat (more or less a 4-tuple)
	-get translation quat from translation vector, rotation quat -> dual quaternion coupling
	-make matrix with rotation part based on rotation quat
	-compute translation vector from translation and rotation quat -> dual quat coupling 
-how to blend dual quats without an explicit representation?
-do you literally just multiply both quaternions by the weight? lol

03/29/2016 - Setting up the MEL [beta: done]


-original PROC provided with plugin
proc connectJointCluster( string $j, int $i )
{
    if ( !objExists( $j+".lockInfluenceWeights" ) )
    {
        select -r $j;
        addAttr -sn "liw" -ln "lockInfluenceWeights" -at "bool";
    }
    connectAttr ($j+".liw") ("HRBFSkinCluster1.lockWeights["+$i+"]");
    connectAttr ($j+".worldMatrix[0]") ("HRBFSkinCluster1.matrix["+$i+"]");
    connectAttr ($j+".objectColorRGB") ("HRBFSkinCluster1.influenceColor["+$i+"]");
	float $m[] = `getAttr ($j+".wim")`;
	setAttr ("HRBFSkinCluster1.bindPreMatrix["+$i+"]") -type "matrix" $m[0] $m[1] $m[2] $m[3] $m[4] $m[5] $m[6] $m[7] $m[8] $m[9] $m[10] $m[11] $m[12] $m[13] $m[14] $m[15];
}

joint -p 1 0 1 ;
joint -p 0 0 0 ; // auto-attaches to last selected joint
joint -e -zso -oj xyz -sao yup joint1; // reorient joint 1
joint -p 1 0 -1 ;
joint -e -zso -oj xyz -sao yup joint2; // reorient joint 2
polyTorus -r 1 -sr 0.5 -tw 0 -sx 50 -sy 50 -ax 0 1 0 -cuv 1 -ch 1;
deformer -type "HRBFSkinCluster";
//setAttr HRBFSkinCluster1.useComponentsMatrix 1; // obsolete
connectJointCluster( "joint1", 0 ); // link joint to skin cluster. TODO: have this take in a string for skin cluster name
connectJointCluster( "joint2", 1 ); // link joint to skin cluster
connectJointCluster( "joint3", 2 ); // link joint to skin cluster
skinCluster -e -maximumInfluences 3 HRBFSkinCluster1;	// forces computation of default weights. we'll import a weight map instead

	polyTorus -r 1 -sr 0.5 -tw 0 -sx 50 -sy 50 -ax 0 1 0 -cuv 1 -ch 1;
	string $clusterStr[] = `deformer -type "basicSkinCluster"`;
	print($clusterStr);

-this little sequence of commands will make a torus, make a skin cluster attached, and hand you the name of said cluster

	ls -sl

-this will list the selected stuff in order of selection. you can do:
	
	string $selectedNodes[] = `ls -sl`;
	print($selectedNodes[0]);

	string $selectedNodes[] = `ls -sl`;
	for ($i = 0; $i < size($selectedNodes); $i++) {
	    print("type: " + `objectType $selectedNodes[$i]`);
	    print(" name: ");
	    print($selectedNodes[$i]);
	    print("\n");    
	}

-this is how you walk over the joints of a skeleton

	string $rels[] = `listRelatives -ad "joint1"`;
	print($rels);

-the workflow we're going through will be something like:
	-select mesh
	-select skeleton
	-run script to attach bones to skin -> eventually, will be tied into UI
	-import skin weights



**********************************************************************************
MAYA INTERACTION NOTES
-ok. skinning is a type of DEFORMER using SKIN CLUSTERS
-with all DEFORMERS you can set the envelope, which is like how much the deformer is actually applied
	-this is in deformer attributes
	-presumably this is what the maya documentation means by percent command
-

********************************************************************************
-we'll need a main -> doyyyy
-we'll need a gl viewer wrapper -> to be reused a lot later? -> look at GL code
-we'll need a scene to manage drawables
-we'll need a drawable subclass
	-GL buffers
	-get vertex buffer
	-get index buffer
	-get normal buffer

-we'll include a dedicated mesh drawable class
-HRBF draw will be a subclass of this
	-but HRBF itself will have to be a separate class

-HRBF segment will voxelize and push all the cubes to GL? is that crazy?
-maybe we'll do points for now... less taxing on the GPU?

TODO
-set up a starter repo using the 563 GL basecode (skeleton)
	-get GLFW working
	-get a basic drawable cube class working -> refer back to 460 for classing, subclassing
-get a basic mesh loader going
-think about how to visualize the HRBF
	-right now I'm thinking voxels